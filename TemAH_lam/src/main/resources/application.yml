server:
  port: 8040
  servlet:
    encoding:
      charset: UTF-8
      enabled: true

spring:
  application:
    name: temah.lam
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://192.168.2.105:3306/test
    username: root
    password: 123456
  boot:
    admin:
      client:
        url: http://localhost:9010 # Spring Boot Admin Server URL用于注册
        instance:
          service-host-type: ip # 使用ip注册进来
        username: admin # Spring Boot Admin Server 注册使用的账户密码
        password: admin
  kafka:
    bootstrap-servers: 192.168.2.105:9092,192.168.2.105:9093,192.168.2.105:9094 # kafka集群信息
    producer: # 生产者配置
      retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送
      batch-size: 16384 #16K
      buffer-memory: 33554432 #32M
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: zhTestGroup # 消费者组
      enable-auto-commit: false # 关闭自动提交
      auto-offset-reset: earliest # 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # RECORD
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交
      # BATCH
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交
      # TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交
      # COUNT
      # TIME |　COUNT　有一个条件满足时提交
      # COUNT_TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # MANUAL
      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种
      # MANUAL_IMMEDIATE
      ack-mode: manual_immediate

mybatis:
  config-location: classpath:mybatis/mybatis-config.xml
  mapper-locations:
    - classpath:mapper/*.xml
    - classpath:mapper/**/*.xml
  type-aliases-package: com.temah.lam.model

management: # actuator打开SpringBoot Admin使用的监控端点
  endpoint:
    health:
      show-details: always
  endpoints:
    web:
      exposure:
        include: '*' # 通过http暴露所有端点
  info:
    env:
      enabled: true # 启用env信息

alarm:
    consumer:
      address: "127.0.0.1:8001"
      restful:
        enable: false
        uri: http://${alarm.consumer.address}/alarm/new
      kafka:
        enable: true
        topic: topic_alarm